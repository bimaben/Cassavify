{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sonoAI.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bimaben/Cassavify/blob/master/sonoAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPLn8qWHLffP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNppO7J4Lmxk",
        "colab_type": "text"
      },
      "source": [
        "here mounting google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGgIzEt-Ew8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "root_path = '/content/drive/My Drive/ mfeyti documents/SONOAI/Programming/data/sono'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIYEVvAAQ1-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path = '/content/drive/My Drive/ mfeyti documents/SONOAI/Programming/data/sono'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aL3XTtRFyb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import keras \n",
        "from keras_preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJDHXWU3L-GK",
        "colab_type": "text"
      },
      "source": [
        "here I am setting up the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuQot0EOLeA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from keras.models import Sequential, load_model, Model\n",
        "from keras.layers import Conv2D, Dropout, Dense, Activation, MaxPooling2D,Flatten\n",
        "from keras.optimizers import rmsprop ,sgd , SGD, Adam\n",
        "from keras.preprocessing import image\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.applications import VGG16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzafgF8jMLKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "here getting Vgg16 to start"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQKvGF-DPJBj",
        "colab_type": "text"
      },
      "source": [
        "here getting Vgg16 to start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dCYXkAvMJm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newmodel = VGG16(include_top=True, weights='imagenet' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNjJnB89MVaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEK_AMt8MWIr",
        "colab_type": "text"
      },
      "source": [
        "**and here is a summary of the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X7lvmX-Mbrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newmodel.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc-FGQajMuqK",
        "colab_type": "text"
      },
      "source": [
        "trying to futher look at the layes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1A-oNzQMx9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, layer in enumerate(newmodel.layers):\n",
        "   print(i, layer.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuFhbhqeM63q",
        "colab_type": "text"
      },
      "source": [
        "here we will try to edit beginning at 15\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrHkEOzYM-Zk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in newmodel.layers[:15]:\n",
        "   layer.trainable = False\n",
        "for layer in newmodel.layers[15:]:\n",
        "   layer.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVrxehLtNEXz",
        "colab_type": "text"
      },
      "source": [
        "try a model that's trainable \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxSGaoz3NHYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainable_layers()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUUQAtyjNLCA",
        "colab_type": "text"
      },
      "source": [
        "transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Veo1IF-WNNCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transfer_layer = newmodel.get_layer('block5_pool')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDVZpbMbNOw7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9SJhJnqNSvm",
        "colab_type": "text"
      },
      "source": [
        "more transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvMpFa7nNVQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_model = Model(inputs=newmodel.input,\n",
        "                   outputs=transfer_layer.output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag5hMS7ENadh",
        "colab_type": "text"
      },
      "source": [
        "putting a new model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUYfrgfkNcuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start a new Keras Sequential model.\n",
        "new_model = Sequential()\n",
        "\n",
        "# Add the convolutional part of the VGG16 model from above.\n",
        "new_model.add(conv_model)\n",
        "\n",
        "# Flatten the output of the VGG16 model because it is from a\n",
        "# convolutional layer.\n",
        "new_model.add(Flatten())\n",
        "\n",
        "# Add a dense (aka. fully-connected) layer.\n",
        "# This is for combining features that the VGG16 model has\n",
        "# recognized in the image.\n",
        "new_model.add(Dense(1024, activation='relu'))\n",
        "\n",
        "# Add a dropout-layer which may prevent overfitting and\n",
        "# improve generalization ability to unseen data e.g. the test-set.\n",
        "new_model.add(Dropout(0.5))\n",
        "\n",
        "# Add the final layer for the actual classification.\n",
        "new_model.add(Dense(5, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poI_4nLlNhPf",
        "colab_type": "text"
      },
      "source": [
        "here new model further edit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c54fI-QTNkFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model.compile(loss='categorical_crossentropy', optimizer= 'Adam', metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27opM8uDNoli",
        "colab_type": "text"
      },
      "source": [
        "training it\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QTkoXgQNqVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history= new_model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=100,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=100,\n",
        "                    epochs=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwrotIeNN4Qs",
        "colab_type": "text"
      },
      "source": [
        "its more absout here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNfMzDYJN7Hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                 input_shape=(200,200,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(512, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(512, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(512, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(512, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "\n",
        "# # define 1st conv layer\n",
        "# model.add(Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(200, 200, 3)))\n",
        "# #pooling\n",
        "# model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "# #normalization\n",
        "# model.add(BatchNormalization())\n",
        "\n",
        "# #2nd conv layer\n",
        "# model.add(Conv2D(256, kernel_size=(5, 5), activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "# model.add(BatchNormalization())\n",
        "\n",
        "# #3rd, 4th, 5th conv layers\n",
        "# model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "# model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
        "# model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "# model.add(BatchNormalization())\n",
        "\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(4096, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(4096, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "# ## Dense fully connected layer with Softmax activation \n",
        "# ## to classify the 5 images\n",
        "# model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "admme =Adam(lr=0.003, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "frt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer= admme, metrics=[\"accuracy\"])\n",
        "              \n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
        "\n",
        "history = model.fit_generator(generator=train_generator,\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=STEP_SIZE_VALID,\n",
        "                    epochs=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeoSiyyQOC5q",
        "colab_type": "text"
      },
      "source": [
        "newer model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0BXBfunOEnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(history.history.keys())\n",
        "# model.save('air_model_6434.h5')\n",
        "#model.save('air_model_4585.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o8oiWC-OH8G",
        "colab_type": "text"
      },
      "source": [
        "generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BV2m0WEOJM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate_generator(validation_generator, steps = 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd861Oh8OM7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('validation Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['val_acc','acc'],loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Training Loss')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['val_loss','loss'],loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MRWLMBfOS6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "air_model = load_model('air_model_4585.h5')\n",
        "air_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=[\"accuracy\"])\n",
        "import os\n",
        "import glob\n",
        "path_img = 'test/0/'\n",
        "imagefiles = glob.glob(path_img + '*.jpg')\n",
        "preds = np.ndarray(shape=(len(imagefiles),1))\n",
        "\n",
        "i=0\n",
        "for imagePath in imagefiles:\n",
        "  test_image = image.load_img(imagePath, target_size = (200, 200)) \n",
        "  test_image = image.img_to_array(test_image)\n",
        "  test_image = np.expand_dims(test_image, axis = 0)\n",
        "\n",
        "  #predict the result\n",
        "  result = air_model.predict(test_image)\n",
        "  preds[i] = np.argmax(result, axis=1)\n",
        "  \n",
        "  i=i+1\n",
        "labels = []\n",
        "for i in preds:\n",
        "  if i == 0:\n",
        "    labels.append('cbb')\n",
        "  elif i == 1:\n",
        "    labels.append('cbsd')\n",
        "  elif i == 2:\n",
        "    labels.append('cgm')\n",
        "  elif i == 3:\n",
        "    labels.append('cmd')\n",
        "  elif i == 4:\n",
        "    labels.append('healthy')\n",
        "\n",
        "names =[]\n",
        "for i in imagefiles:\n",
        "  i= i[7:]\n",
        "  names.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eEkVCgrOaBn",
        "colab_type": "text"
      },
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxj8rIETOa_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#df.to_csv('submission_45.csv', index=False)\n",
        "names"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}